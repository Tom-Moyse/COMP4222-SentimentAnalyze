{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GraphSAGE Classifier"
      ],
      "metadata": {
        "id": "ZyC9OMwfc0Kt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and load environment including necessary modules and files"
      ],
      "metadata": {
        "id": "WDVvstRpc7kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl dglgo -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl import DGLGraph\n",
        "from dgl.data import DGLDataset\n",
        "from dgl.nn.pytorch import conv as dgl_conv\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pickle\n",
        "adja_matrix, unique_keywords = pickle.load(open('/content/drive/MyDrive/hkust_colab/COMP4222/AdjacencyMatrices/200803_201103_AdjacencyMatrix_labeled.pickle', 'rb'))"
      ],
      "metadata": {
        "id": "pIw_N3jAY6mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier Classes and Fuctions, and Dataset Pre-processing"
      ],
      "metadata": {
        "id": "z4LEGeO2dINb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KeywordDataset(DGLDataset):\n",
        "    def __init__(self):\n",
        "        super().__init__(name='keyword_data')\n",
        "\n",
        "    def process(self):\n",
        "        pols = np.zeros((adja_matrix.shape[0], 1))\n",
        "        for index in pol_ids:\n",
        "          #pols[index] = (pol_keywords.loc[[index]]['party'] * 2) - 1\n",
        "          pols[index] = 1\n",
        "        \n",
        "        node_features = torch.from_numpy(pols)\n",
        "        #node_features = F.one_hot(torch.arange(0,adja_matrix.shape[0]))\n",
        "        node_labels = pol_keywords['party'].to_numpy()\n",
        "        node_base_labels = np.random.randint(0, 2, adja_matrix.shape[0])\n",
        "\n",
        "        for count, index in enumerate(pol_ids):\n",
        "          node_base_labels[index] = node_labels[count]\n",
        "\n",
        "        src, dst = np.nonzero(adja_matrix)\n",
        "\n",
        "        self.graph = dgl.graph((src, dst), num_nodes=adja_matrix.shape[0])\n",
        "        self.graph.ndata['feat'] = node_features\n",
        "        self.graph.ndata['label'] = torch.from_numpy(node_base_labels)\n",
        "\n",
        "        # If your dataset is a node classification dataset, you will need to assign\n",
        "        # masks indicating whether a node belongs to training, validation, and test set.\n",
        "        n_nodes = adja_matrix.shape[0]\n",
        "        n_train = int(len(pol_ids) * 0.4)\n",
        "        n_val = int(len(pol_ids) * 0.3)\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "\n",
        "        for count, index in enumerate(pol_ids):\n",
        "          if count < n_train:\n",
        "            train_mask[index] = True\n",
        "          elif count < n_train + n_val:\n",
        "            val_mask[index] = True\n",
        "          else:\n",
        "            test_mask[index] = True\n",
        "\n",
        "        self.graph.ndata['train_mask'] = train_mask\n",
        "        self.graph.ndata['val_mask'] = val_mask\n",
        "        self.graph.ndata['test_mask'] = test_mask\n",
        "\n",
        "        self.features = node_features\n",
        "        self.labels = torch.from_numpy(node_base_labels)\n",
        "        self.num_labels = 2\n",
        "        self.train_mask = train_mask\n",
        "        self.val_mask = val_mask\n",
        "        self.test_mask = test_mask\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.graph\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "class GraphSAGEModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_feats,\n",
        "                 n_hidden,\n",
        "                 out_dim,\n",
        "                 n_layers,\n",
        "                 activation,\n",
        "                 dropout,\n",
        "                 aggregator_type):\n",
        "        super(GraphSAGEModel, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # input layer\n",
        "        self.layers.append(dgl_conv.SAGEConv(in_feats, n_hidden, aggregator_type,\n",
        "                                         feat_drop=dropout, activation=activation))\n",
        "        # hidden layers\n",
        "        for i in range(n_layers - 1):\n",
        "            self.layers.append(dgl_conv.SAGEConv(n_hidden, n_hidden, aggregator_type,\n",
        "                                             feat_drop=dropout, activation=activation))\n",
        "        # output layer\n",
        "        self.layers.append(dgl_conv.SAGEConv(n_hidden, out_dim, aggregator_type,\n",
        "                                         feat_drop=dropout, activation=None))\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        h = features\n",
        "        for layer in self.layers:\n",
        "            h = layer(g, h)\n",
        "        return h\n",
        "\n",
        "class NodeClassification(nn.Module):\n",
        "    def __init__(self, gconv_model, n_hidden, n_classes):\n",
        "        super(NodeClassification, self).__init__()\n",
        "        self.gconv_model = gconv_model\n",
        "        self.loss_fcn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, g, features, train_mask):\n",
        "        logits = self.gconv_model(g, features)\n",
        "        return self.loss_fcn(logits[train_mask], labels[train_mask])\n",
        "\n",
        "def NCEvaluate(model, g, features, labels, test_mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # compute embeddings with GNN\n",
        "        logits = model.gconv_model(g, features)\n",
        "        logits = logits[test_mask]\n",
        "        test_labels = labels[test_mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        #print(indices)\n",
        "        correct = torch.sum(indices == test_labels)\n",
        "        acc = correct.item() * 1.0 / len(test_labels)\n",
        "    return acc\n",
        "\n",
        "def Train(model, graph, features, train_mask, val_mask, labels, n_epochs):\n",
        "    for epoch in range(n_epochs):\n",
        "        # Set the model in the training mode.\n",
        "        model.train()\n",
        "        # forward\n",
        "        loss = model(graph, features, train_mask)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \"\"\"\n",
        "        acc = NCEvaluate(model, graph, features, labels, val_mask)\n",
        "        print(\"Epoch {:05d} | Loss {:.4f} | Accuracy {:.4f}\"\n",
        "            .format(epoch, loss.item(), acc))\n",
        "        \"\"\"\n",
        "def Test(model, graph, features, labels, test_mask):\n",
        "    acc = NCEvaluate(model, graph, features, labels, test_mask)\n",
        "    print('Testing Accuracy:', acc)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "6slKUc4xZ0zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter tuning test script"
      ],
      "metadata": {
        "id": "GUMPtFkFddLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_opts = [1, 4, 8, 16, 64]\n",
        "dropout_opts = [0.01, 0.1, 0.3, 0.5, 0.8]\n",
        "agg_type_opts = ['mean', 'pool', 'gcn']\n",
        "weight_decay_opts = [0, 5e-4, 5e-2]\n",
        "lr_opts = [1e-2, 1e-3, 1e-4]\n",
        "\n",
        "params = itertools.product(hidden_opts, dropout_opts, agg_type_opts, weight_decay_opts, lr_opts)\n",
        "with open('/content/drive/MyDrive/hkust_colab/COMP4222/results.txt', \"a\") as results:\n",
        "  for paramset in params:\n",
        "    random.seed(123)\n",
        "\n",
        "    pol_keywords = unique_keywords[unique_keywords.party.notnull()]\n",
        "    pol_keywords['party'].replace(\"Democratic Party\", 0, True)\n",
        "    pol_keywords['party'].replace(\"Republican Party\", 1, True)\n",
        "    pol_ids = list(pol_keywords.index)\n",
        "    random.shuffle(pol_ids)\n",
        "\n",
        "    dataset = KeywordDataset()\n",
        "\n",
        "    features = torch.DoubleTensor(dataset.features).float()\n",
        "    in_feats = features.shape[1]\n",
        "    labels = torch.LongTensor(dataset.labels)\n",
        "    n_classes = dataset.num_labels\n",
        "\n",
        "    graph = dgl.remove_self_loop(dataset[0])\n",
        "    # Hyperparameters\n",
        "    n_hidden = paramset[0]\n",
        "    n_layers = 2\n",
        "    dropout = paramset[1]\n",
        "    aggregator_type = paramset[2]\n",
        "\n",
        "    gconv_model = GraphSAGEModel(in_feats,\n",
        "                                n_hidden,\n",
        "                                n_classes,\n",
        "                                n_layers,\n",
        "                                F.leaky_relu,\n",
        "                                dropout,\n",
        "                                aggregator_type)\n",
        "\n",
        "    train_mask = graph.ndata['train_mask']\n",
        "    val_mask = graph.ndata['val_mask']\n",
        "    test_mask = graph.ndata['test_mask']\n",
        "\n",
        "    model = NodeClassification(gconv_model, n_hidden, n_classes)\n",
        "\n",
        "    # Training hyperparameters\n",
        "    weight_decay = paramset[3]\n",
        "    n_epochs = 50\n",
        "    lr = paramset[4]\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    Train(model, graph, features, train_mask, val_mask, labels, n_epochs)\n",
        "    acc = Test(model, graph, features, labels, test_mask)\n",
        "    results.write(str(paramset) + \",\\t\\tAcc: \" + str(acc) + \"\\n\")"
      ],
      "metadata": {
        "id": "P93R8S64SOPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Harmonic Node Classification"
      ],
      "metadata": {
        "id": "clhhEjNcdkqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup and load environment including necessary modules and files"
      ],
      "metadata": {
        "id": "QIVNtsVRdrI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from networkx.algorithms import node_classification\n",
        "\n",
        "adja_matrix, unique_keywords = pickle.load(open('/content/drive/MyDrive/hkust_colab/COMP4222/AdjacencyMatrices/200803_201103_AdjacencyMatrix_labeled.pickle', 'rb'))\n",
        "pol_keywords = unique_keywords[unique_keywords.party.notnull()]"
      ],
      "metadata": {
        "id": "C-3zRQUQEF5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Harmonic classification test script with data preprocessing"
      ],
      "metadata": {
        "id": "ekIpnnTfd_JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_acc_cum = 0\n",
        "d_acc_cum = 0\n",
        "\n",
        "\"\"\"\n",
        "Past results with diff iter-num\n",
        "3: R-acc = 0.626, D-acc = 0.716\n",
        "5: R-acc = 0.579, D-acc = 0.735\n",
        "10: R-acc = 0.519, D-acc = 0.770\n",
        "\"\"\"\n",
        "\n",
        "for test_num in range(1, 11):\n",
        "  KeywordGraph = nx.from_numpy_matrix(adja_matrix)\n",
        "\n",
        "  # Label all but 30 nodes\n",
        "  not_labelled = list((pol_keywords.sample(n=30, random_state=test_num)).index)\n",
        "  repub_sample = 0\n",
        "  democ_sample = 0\n",
        "\n",
        "  for i, info in pol_keywords.iterrows(): \n",
        "    if i in not_labelled:\n",
        "      if pol_keywords.loc[i]['party'][0] == 'R': repub_sample += 1\n",
        "      else: democ_sample += 1\n",
        "\n",
        "    if not (i in not_labelled):\n",
        "      KeywordGraph.nodes[i][\"party\"] = info[\"party\"][0]\n",
        "\n",
        "  predicted = node_classification.harmonic_function(KeywordGraph, label_name=\"party\", max_iter=5)\n",
        "  repub_count = 0\n",
        "  democ_count = 0\n",
        "\n",
        "\n",
        "  repub_correct = 0\n",
        "  democ_correct = 0\n",
        "  for i, p in enumerate(predicted):\n",
        "    if i in not_labelled:\n",
        "      if pol_keywords.loc[i]['party'][0] == p:\n",
        "        if p == 'R': repub_correct += 1\n",
        "        else: democ_correct += 1\n",
        "\n",
        "    if p == 'R': repub_count += 1\n",
        "    else: democ_count += 1\n",
        "\n",
        "  #print(f\"Test No: {test_num}, Repub No: {repub_count}, Democ No: {democ_count}, Repub Samples: {repub_sample}, Democ Samples: {democ_sample}, Repub Correct: {repub_correct}, Democ Correct: {democ_correct}\")\n",
        "  repub_acc = repub_correct / repub_sample\n",
        "  democ_acc = democ_correct / democ_sample\n",
        "  r_acc_cum += repub_acc\n",
        "  d_acc_cum += democ_acc\n",
        "  print(f\"Test No: {test_num}, Republican Acc: {repub_acc:f}, Democratic Acc: {democ_acc:f}\")\n",
        "\n",
        "print(f\"10 Pass Results: Republican Acc: {r_acc_cum / 10:f}, Democratic Acc: {d_acc_cum / 10:f}\")"
      ],
      "metadata": {
        "id": "wGlHhJDTwux3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}